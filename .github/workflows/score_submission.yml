name: Score Submission

on:
  push:
    branches:
      - main
    paths:
      - 'submissions/**'
      - '!submissions/README.md'
  pull_request:
    paths:
      - 'submissions/**'
      - '!submissions/README.md'
      - '!submissions/encrypt_submission.py'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: write
      statuses: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install pandas scikit-learn pyyaml pycryptodome

      - name: Run Evaluation
        id: eval_step
        env:
          TEST_LABELS: ${{ secrets.TEST_LABELS }}
          RSA_PRIVATE_KEY: ${{ secrets.RSA_PRIVATE_KEY }}
        run: |
          # 1. Find the file and team
          SUBMISSION_FILE=$(find submissions -name "*.enc" | head -n 1)
          if [ -z "$SUBMISSION_FILE" ]; then echo "ERROR: No file found"; exit 1; fi
          TEAM_NAME=$(basename $(dirname "$SUBMISSION_FILE"))
          
          # 2. Run evaluation
          python competition/evaluate.py --file "$SUBMISSION_FILE" | tee evaluation_output.txt
          
          # 3. Parse score
          SCORE=$(grep "SCORE_MAE" evaluation_output.txt | awk '{print $2}')
          
          # 4. CRITICAL: Save to outputs
          echo "score=$SCORE" >> $GITHUB_OUTPUT
          echo "team_name=$TEAM_NAME" >> $GITHUB_OUTPUT
          
          # 5. Debug (Check your logs for this!)
          echo "Debug: Team is $TEAM_NAME and Score is $SCORE"

      - name: Update Leaderboard Data
        if: steps.eval_step.outputs.score != ''
        run: |
          TEAM="${{ steps.eval_step.outputs.team_name }}"
          SCORE="${{ steps.eval_step.outputs.score }}"
          SUBMISSION_TIME=$(date -u +"%b %d, %H:%M UTC")

          mkdir -p leaderboard
          
          # 1. Update CSV (Append new result)
          if [ ! -f leaderboard/leaderboard.csv ]; then echo "team,mae,date" > leaderboard/leaderboard.csv; fi
          echo "$TEAM,$SCORE,$SUBMISSION_TIME" >> leaderboard/leaderboard.csv
          
          # 2. Process CSV with Python (Sort and keep best score per team)
          python3 -c "
          import pandas as pd
          df = pd.read_csv('leaderboard/leaderboard.csv')
          df['mae'] = pd.to_numeric(df['mae'], errors='coerce')
          df = df.dropna(subset=['mae']).sort_values('mae').drop_duplicates('team', keep='first')
          df.to_csv('leaderboard/leaderboard.csv', index=False)
          "

          # 3. Regenerate Markdown LEADERBOARD.md
          echo "# üèÜ Competition Leaderboard" > leaderboard/LEADERBOARD.md
          echo "Last updated: $(date -u)" >> leaderboard/LEADERBOARD.md
          echo "" >> leaderboard/LEADERBOARD.md
          echo "| Rank | Team | MAE Score | Submission Time |" >> leaderboard/LEADERBOARD.md
          echo "|------|------|-----------|-----------------|" >> leaderboard/LEADERBOARD.md
          
          # This line takes the sorted CSV and formats it into the Markdown table
          tail -n +2 leaderboard/leaderboard.csv | awk -F, '{print "| " NR " | " $1 " | " $2 " | " $3 " |"}' >> leaderboard/LEADERBOARD.md

      - name: Push changes back to main
        if: github.event_name == 'push' && steps.eval_step.outputs.score != ''
        run: |
          git config user.name "Leaderboard Bot"
          git config user.email "actions@github.com"
          git add leaderboard/
          git commit -m "Update leaderboard: ${{ steps.eval_step.outputs.team_name }}" || echo "No changes"
          git push origin HEAD:main

      - name: Post Score to Pull Request
        uses: mshick/add-pr-comment@v2
        if: always()
        with:
          message: |
            ## üß† Brain-Age GNN Result
            **Status:** ${{ steps.eval_step.outputs.score != '' && '‚úÖ Success' || '‚ùå Evaluation Failed' }}
            **Team:** `${{ steps.eval_step.outputs.team_name }}`
            **Score (MAE):** `${{ steps.eval_step.outputs.score || 'N/A' }}`